# ğŸ‡»ğŸ‡³ Vietnamese Hate Speech Detection Pipeline

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![Transformers](https://img.shields.io/badge/library-transformers-orange.svg)](https://github.com/huggingface/transformers)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

Má»™t há»‡ thá»‘ng toÃ n diá»‡n cho bÃ i toÃ¡n phÃ¡t hiá»‡n ngÃ´n ngá»¯ thÃ¹ ghÃ©t (Hate Speech) vÃ  bÃ¬nh luáº­n Ä‘á»™c háº¡i (Toxic Speech) tiáº¿ng Viá»‡t, sá»­ dá»¥ng cÃ¡c kiáº¿n trÃºc SOTA nhÆ° **PhoBERT/ViSoBERT** vÃ  **T5/ViT5**.

---

## ğŸ“Œ Tá»•ng quan dá»± Ã¡n

Dá»± Ã¡n cung cáº¥p 3 pipeline chÃ­nh cho phÃ©p báº¡n Ä‘i tá»« dá»¯ liá»‡u thÃ´ Ä‘áº¿n mÃ´ hÃ¬nh hoÃ n chá»‰nh:
1.  **Pre-training**: Tiáº¿p tá»¥c huáº¥n luyá»‡n T5 vá»›i cÆ¡ cháº¿ *Span Corruption* trÃªn dá»¯ liá»‡u tiáº¿ng Viá»‡t.
2.  **T5 Fine-tuning**: Huáº¥n luyá»‡n Seq2Seq cho bÃ i toÃ¡n phÃ¢n loáº¡i Ä‘a táº­p dá»¯ liá»‡u.
3.  **BERT Classification**: Huáº¥n luyá»‡n cÃ¡c mÃ´ hÃ¬nh Encoder-only (PhoBERT, ViSoBERT) truyá»n thá»‘ng.

---

## ğŸ›  CÃ i Ä‘áº·t & Chuáº©n bá»‹

### 1. Khá»Ÿi táº¡o mÃ´i trÆ°á»ng
```bash
# Khá»Ÿi táº¡o venv
python -m venv .venv
source .venv/bin/activate  # Linux/Mac
# Windows: .venv\Scripts\activate

# CÃ i Ä‘áº·t thÆ° viá»‡n
pip install -r requirements.txt
```

### 2. ÄÄƒng nháº­p HuggingFace (Cáº§n thiáº¿t Ä‘á»ƒ táº£i/Ä‘áº©y mÃ´ hÃ¬nh)
```bash
huggingface-cli login
# Hoáº·c thiáº¿t láº­p biáº¿n mÃ´i trÆ°á»ng HF_TOKEN
```

---

## ğŸ“Š Dá»¯ liá»‡u (Datasets)

Há»‡ thá»‘ng há»— trá»£ náº¡p dá»¯ liá»‡u tá»± Ä‘á»™ng tá»« HuggingFace hoáº·c file local:

| TÃªn Dataset | Loáº¡i | MÃ´ táº£ |
| :--- | :--- | :--- |
| **ViHSD** | Multi-class | 3 nhÃ£n: CLEAN, OFFENSIVE, HATE |
| **ViCTSD** | Binary | PhÃ¡t hiá»‡n Ä‘á»™c háº¡i (Toxic/None) |
| **ViHOS** | Hate Spans | PhÃ¡t hiá»‡n vÃ¹ng thÃ¹ ghÃ©t |
| **VOZ-HSD** | Binary | Dá»¯ liá»‡u lá»›n (balanced, hate_only, full) |
| **Custom HF** | TÃ¹y chá»n | Báº¥t ká»³ dataset nÃ o trÃªn HuggingFace (tá»± nháº­n diá»‡n cá»™t) |

---

## ğŸš€ HÆ°á»›ng dáº«n sá»­ dá»¥ng (Scripts)

ChÃºng tÃ´i cung cáº¥p cÃ¡c script bash trong thÆ° má»¥c `scripts/` Ä‘á»ƒ cháº¡y nhanh vá»›i cÃ¡c tham sá»‘ tá»‘i Æ°u.

### 1. Pre-training T5 (Span Corruption)
Sá»­ dá»¥ng khi báº¡n muá»‘n mÃ´ hÃ¬nh T5 hiá»ƒu sÃ¢u hÆ¡n vá» ngá»¯ cáº£nh dá»¯ liá»‡u Ä‘áº·c thÃ¹ cá»§a mÃ¬nh.

```bash
bash scripts/run_pretrain_t5.sh \
    --dataset_name "Minhbao5xx2/re_VOZ-HSD" \
    --split_name "hate_only" \
    --max_samples 50000
```
*LÆ°u Ã½: Script Ä‘Æ°á»£c tá»‘i Æ°u máº·c Ä‘á»‹nh cho GPU H200. Náº¿u dÃ¹ng GPU nhá» hÆ¡n, hÃ£y Ä‘iá»u chá»‰nh `batch_size` trong code.*

### 2. Fine-tuning T5 (PhÃ¢n loáº¡i Seq2Seq)
Huáº¥n luyá»‡n mÃ´ hÃ¬nh sinh ra nhÃ£n vÄƒn báº£n (vÃ­ dá»¥: "HATE", "CLEAN").

```bash
bash scripts/run_train_t5.sh \
    --pre_trained_ckpt "VietAI/vit5-base" \
    --batch_size 32 \
    --num_epochs 4 \
    --gpu "0"
```

### 3. Huáº¥n luyá»‡n BERT/PhoBERT (Classification)
CÃ¡ch tiáº¿p cáº­n truyá»n thá»‘ng sá»­ dá»¥ng Classification Head.

```bash
bash scripts/run_train_bert.sh \
    --dataset "ViHSD" \
    --model_name "vinai/phobert-base" \
    --epochs 10 \
    --patience 3
```

---

## âš™ï¸ Chi tiáº¿t tham sá»‘ (CLI Arguments)

### CÃ¡c tham sá»‘ chung cho cÃ¡c Script:
| Tham sá»‘ | MÃ´ táº£ | Máº·c Ä‘á»‹nh |
| :--- | :--- | :--- |
| `--dataset` | TÃªn dataset hoáº·c Ä‘Æ°á»ng dáº«n HF | `ViHSD` |
| `--model_name` | Model checkpoint tá»« HuggingFace | `vinai/phobert-base` |
| `--batch_size` | KÃ­ch thÆ°á»›c batch huáº¥n luyá»‡n | `16` |
| `--epochs` | Sá»‘ lÆ°á»£ng epoch huáº¥n luyá»‡n | `10` |
| `--learning_rate`| Tá»‘c Ä‘á»™ há»c | `2e-5` |
| `--output_dir` | ThÆ° má»¥c lÆ°u káº¿t quáº£ | Tá»± Ä‘á»™ng sinh |

---

## ğŸ“ˆ Káº¿t quáº£ & Output

Sau khi cháº¡y training, káº¿t quáº£ sáº½ Ä‘Æ°á»£c lÆ°u vÃ o thÆ° má»¥c `outputs/` hoáº·c `vihate_t5_pretrain/`:

-   **Model Checkpoints**: File trá»ng sá»‘ (`.bin` / `.safetensors`) vÃ  cáº¥u hÃ¬nh.
-   **`run_summary.csv`**: Tá»•ng há»£p káº¿t quáº£ tá»‘t nháº¥t (F1, Accuracy, Loss).
-   **`epoch_metrics.csv`**: Chi tiáº¿t cÃ¡c chá»‰ sá»‘ qua tá»«ng epoch.
-   **`results/evaluation_results.csv`**: (DÃ nh riÃªng cho T5) Káº¿t quáº£ Ä‘Ã¡nh giÃ¡ trÃªn cÃ¡c táº­p test riÃªng biá»‡t.

---

## ğŸ’¡ Tá»‘i Æ°u hÃ³a hiá»‡u nÄƒng (Hardware Tips)

TÃ¹y vÃ o cáº¥u hÃ¬nh pháº§n cá»©ng, báº¡n nÃªn Ä‘iá»u chá»‰nh cÃ¡c tham sá»‘ sau Ä‘á»ƒ Ä‘áº¡t tá»‘c Ä‘á»™ cao nháº¥t:

-   **GPU H200 (141GB)**: CÃ³ thá»ƒ dÃ¹ng `batch_size=512` cho pre-training.
-   **GPU A100/A800**: Khuyáº¿n nghá»‹ `batch_size=128-256`.
-   **GPU Phá»• thÃ´ng (8GB-16GB)**: 
    -   Báº­t `gradient_checkpointing=True`.
    -   Sá»­ dá»¥ng `gradient_accumulation_steps` Ä‘á»ƒ bÃ¹ Ä‘áº¯p batch size nhá».
    -   Giáº£m `max_length` xuá»‘ng 128 náº¿u bá»‹ OOM.

---

## ğŸ“‚ Cáº¥u trÃºc thÆ° má»¥c

```text
.
â”œâ”€â”€ src/                    # MÃ£ nguá»“n chÃ­nh (Python)
â”‚   â”œâ”€â”€ pre_train_t5.py    # Script pre-training
â”‚   â”œâ”€â”€ train_t5.py         # Script fine-tuning T5
â”‚   â”œâ”€â”€ train_bert.py       # Script huáº¥n luyá»‡n BERT
â”‚   â””â”€â”€ data_loader.py      # Xá»­ lÃ½ náº¡p dá»¯ liá»‡u
â”œâ”€â”€ scripts/                # Bash scripts cháº¡y nhanh
â”œâ”€â”€ outputs/                # LÆ°u trá»¯ model checkpoints
â”œâ”€â”€ results/                # LÆ°u trá»¯ káº¿t quáº£ Ä‘Ã¡nh giÃ¡ (CSV)
â””â”€â”€ requirements.txt        # Danh sÃ¡ch thÆ° viá»‡n cáº§n thiáº¿t
```

---

## âš ï¸ Giáº£i quyáº¿t sá»± cá»‘ thÆ°á»ng gáº·p

1.  **Lá»—i OOM (Out of Memory)**: Giáº£m `batch_size` hoáº·c `max_length`.
2.  **KhÃ´ng tÃ¬m tháº¥y module**: Äáº£m báº£o báº¡n Ä‘Ã£ `pip install -r requirements.txt` vÃ  cháº¡y script tá»« thÆ° má»¥c gá»‘c.
3.  **Lá»—i náº¡p Dataset**: Kiá»ƒm tra káº¿t ná»‘i máº¡ng vÃ  Ä‘áº£m báº£o tÃªn dataset trÃªn HuggingFace lÃ  chÃ­nh xÃ¡c.

---
Â© 2024 Vietnamese Hate Speech Team. Dá»± Ã¡n phá»¥c vá»¥ má»¥c Ä‘Ã­ch nghiÃªn cá»©u.
